{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME_ANOMALY = \"replace_by_speical_tag_CNA_title_adjust.json\"\n",
    "FILENAME_NORMAL_1 = \"replace_by_speical_tag_Gossip_title_20000_to_39088_adjust.json\"\n",
    "FILENAME_NORMAL_2_1 = \"replace_by_speical_tag_katino_data_adjust.json\"\n",
    "FILENAME_NORMAL_2_2 = \"replace_by_speical_tag_coco_title_category_1_to_121_MAX_1000_adjust.json\"\n",
    "SPILT_RATE = 0.2\n",
    "NAME_FRONT = \"v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./preo_data/%s\" % FILENAME_ANOMALY) as json_file:\n",
    "    anomaly_data = json.load(json_file)\n",
    "    \n",
    "with open(\"./preo_data/%s\" % FILENAME_NORMAL_1) as json_file:\n",
    "    normal_data_1 = json.load(json_file)\n",
    "    \n",
    "with open(\"./preo_data/%s\" % FILENAME_NORMAL_2_1) as json_file:\n",
    "    normal_data_2_1 = json.load(json_file)\n",
    "    \n",
    "with open(\"./preo_data/%s\" % FILENAME_NORMAL_2_2) as json_file:\n",
    "    normal_data_2_2 = json.load(json_file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(anomaly_data)\n",
    "random.shuffle(normal_data_1)\n",
    "random.shuffle(normal_data_2_1)\n",
    "random.shuffle(normal_data_2_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For normal data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2_len = min(len(normal_data_2_1), len(normal_data_2_2))*2\n",
    "train_len = min(len(normal_data_1), train_2_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normal_data = np.array(normal_data_1[:2*(train_len//2)] + normal_data_2_1[:train_len//2] + normal_data_2_1[:train_len//2])\n",
    "X_normal_data = normal_data_1[:2*(train_len//2)] + normal_data_2_1[:train_len//2] + normal_data_2_1[:train_len//2]\n",
    "Y_normal_data = list(np.repeat((1, 2), len(X_normal_data)/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spilt-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_normal_train, X_normal_test, y_normal_train, y_normal_test = train_test_split(X_normal_data, \n",
    "                                                                                Y_normal_data, \n",
    "                                                                                test_size = SPILT_RATE)\n",
    "\n",
    "# for json save\n",
    "y_normal_train = [int(i) for i in y_normal_train]\n",
    "y_normal_test = [int(i) for i in y_normal_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./preo_data/%s_X_normal_train.json\" % NAME_FRONT, 'w') as outfile:\n",
    "    json.dump(X_normal_train, outfile)\n",
    "    \n",
    "with open(\"./preo_data/%s_X_normal_test.json\" % NAME_FRONT, 'w') as outfile:\n",
    "    json.dump(X_normal_test, outfile)\n",
    "    \n",
    "with open(\"./preo_data/%s_y_normal_train.json\" % NAME_FRONT, 'w') as outfile:\n",
    "    json.dump(y_normal_train, outfile)\n",
    "    \n",
    "with open(\"./preo_data/%s_y_normal_test.json\" % NAME_FRONT, 'w') as outfile:\n",
    "    json.dump(y_normal_test, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For anomaly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_anomaly_data = anomaly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_anomaly_data = list(np.repeat(0, len(X_anomaly_data)))\n",
    "# for json save\n",
    "Y_anomaly_data = [int(i) for i in Y_anomaly_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./preo_data/%s_X_anomaly_data.json\" % NAME_FRONT, 'w') as outfile:\n",
    "    json.dump(X_anomaly_data, outfile)\n",
    "    \n",
    "with open(\"./preo_data/%s_Y_anomaly_data.json\" % NAME_FRONT, 'w') as outfile:\n",
    "    json.dump(Y_anomaly_data, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
